{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ3mgAt8vTWEGOWn7mmbf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HriddhiDoley/Supply_Chain/blob/main/Sales_forecasting_sentiments_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe0nvDMFyAWK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import feedparser\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Download necessary NLP package\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load sales data (Favorita Grocery Sales Dataset from Kaggle)\n",
        "sales_data = pd.read_csv('https://www.kaggleusercontent.com/datasets/rohanrao/store-sales-time-series-forecasting/data.csv')\n",
        "sales_data = sales_data[['date', 'sales']]\n",
        "sales_data.columns = ['Date', 'Sales']\n",
        "sales_data['Date'] = pd.to_datetime(sales_data['Date'])\n",
        "sales_data.set_index('Date', inplace=True)\n",
        "\n",
        "# Normalize sales data\n",
        "scaler = MinMaxScaler()\n",
        "sales_data['Sales'] = scaler.fit_transform(sales_data[['Sales']])\n",
        "\n",
        "# Fetch news sentiment from Google News RSS Feed\n",
        "rss_url = \"https://news.google.com/rss/search?q=retail+sales&hl=en-US&gl=US&ceid=US:en\"\n",
        "news_feed = feedparser.parse(rss_url)\n",
        "news_headlines = [entry.title for entry in news_feed.entries[:10]]\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = [sia.polarity_scores(headline)['compound'] for headline in news_headlines]\n",
        "news_sentiment = np.mean(sentiment_scores)  # Aggregate sentiment score\n",
        "\n",
        "# Add sentiment as a feature\n",
        "sales_data['Sentiment'] = news_sentiment\n",
        "\n",
        "# Prepare data for LSTM\n",
        "sequence_length = 5\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data.iloc[i:i+seq_length].values)\n",
        "        y.append(data.iloc[i+seq_length]['Sales'])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(sales_data, sequence_length)\n",
        "\n",
        "# Split into training and testing sets\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(sequence_length, 2)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict and plot\n",
        "predictions = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
        "actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(actual, label='Actual Sales')\n",
        "plt.plot(predictions, label='Predicted Sales', linestyle='dashed')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}